# Open WebUI Docker ä½¿ç”¨æ•™ç¨‹

## ğŸ“‹ ç›®å½•
- [æ„å»ºé•œåƒ (Docker Build)](#æ„å»ºé•œåƒ-docker-build)
- [è¿è¡Œå®¹å™¨ (Docker Run)](#è¿è¡Œå®¹å™¨-docker-run)
- [æ¨é€é•œåƒ (Docker Push)](#æ¨é€é•œåƒ-docker-push)
- [æ‹‰å–é•œåƒ (Docker Pull)](#æ‹‰å–é•œåƒ-docker-pull)
- [æ•°æ®å·ç®¡ç†](#æ•°æ®å·ç®¡ç†)
- [ç¯å¢ƒå˜é‡é…ç½®](#ç¯å¢ƒå˜é‡é…ç½®)
- [è‡ªå®šä¹‰ä¿®æ”¹](#è‡ªå®šä¹‰ä¿®æ”¹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”¨ æ„å»ºé•œåƒ (Docker Build)

### åŸºç¡€æ„å»º
```bash
# åŸºç¡€æ„å»ºï¼ˆCPUç‰ˆæœ¬ï¼‰
docker build -t open-webui:latest .

# æ„å»ºæ—¶æŒ‡å®šç‰ˆæœ¬æ ‡ç­¾
docker build -t open-webui:v0.6.15 .
```

### å¸¦æ„å»ºå‚æ•°çš„æ„å»º
```bash
# CUDA GPUæ”¯æŒç‰ˆæœ¬
docker build \
  --build-arg USE_CUDA=true \
  --build-arg USE_CUDA_VER=cu128 \
  -t open-webui:cuda .

# Ollamaé›†æˆç‰ˆæœ¬
docker build \
  --build-arg USE_OLLAMA=true \
  -t open-webui:ollama .

# è‡ªå®šä¹‰åµŒå…¥æ¨¡å‹
docker build \
  --build-arg USE_EMBEDDING_MODEL=intfloat/multilingual-e5-large \
  -t open-webui:multilingual .

# å®Œæ•´é…ç½®æ„å»º
docker build \
  --build-arg USE_CUDA=true \
  --build-arg USE_OLLAMA=true \
  --build-arg USE_CUDA_VER=cu128 \
  --build-arg USE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2 \
  --build-arg BUILD_HASH=v0.6.15 \
  -t open-webui:full .
```

### æ„å»ºå‚æ•°è¯´æ˜
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `USE_CUDA` | `false` | å¯ç”¨CUDA GPUæ”¯æŒ |
| `USE_OLLAMA` | `false` | é›†æˆOllamaæœåŠ¡ |
| `USE_CUDA_VER` | `cu128` | CUDAç‰ˆæœ¬ (cu117/cu121/cu128) |
| `USE_EMBEDDING_MODEL` | `sentence-transformers/all-MiniLM-L6-v2` | åµŒå…¥æ¨¡å‹ |
| `USE_RERANKING_MODEL` | `""` | é‡æ’åºæ¨¡å‹ |
| `BUILD_HASH` | `dev-build` | æ„å»ºç‰ˆæœ¬æ ‡è¯† |

---

## ğŸš€ è¿è¡Œå®¹å™¨ (Docker Run)

### åŸºç¡€è¿è¡Œ
```bash
# åŸºç¡€è¿è¡Œ
docker run -d \
  --name open-webui \
  -p 3000:8080 \
  -v open-webui:/app/backend/data \
  --restart unless-stopped \
  open-webui:latest
```

### å®Œæ•´é…ç½®è¿è¡Œ
```bash
# å®Œæ•´é…ç½®è¿è¡Œ
docker run -d \
  --name open-webui \
  -p 3000:8080 \
  -v open-webui-data:/app/backend/data \
  -v open-webui-cache:/app/backend/data/cache \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e WEBUI_SECRET_KEY=your_secret_key \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  --add-host=host.docker.internal:host-gateway \
  --restart unless-stopped \
  open-webui:latest
```

### GPUæ”¯æŒè¿è¡Œ
```bash
# CUDA GPUæ”¯æŒ
docker run -d \
  --name open-webui-gpu \
  --gpus all \
  -p 3000:8080 \
  -v open-webui-data:/app/backend/data \
  --restart unless-stopped \
  open-webui:cuda
```

### Ollamaé›†æˆè¿è¡Œ
```bash
# å†…ç½®Ollamaç‰ˆæœ¬
docker run -d \
  --name open-webui-ollama \
  -p 3000:8080 \
  -v ollama-data:/root/.ollama \
  -v open-webui-data:/app/backend/data \
  --restart unless-stopped \
  open-webui:ollama
```

---

## ğŸ“¤ æ¨é€é•œåƒ (Docker Push)

### æ¨é€åˆ°Docker Hub
```bash
# 1. ç™»å½•Docker Hub
docker login

# 2. ç»™é•œåƒæ‰“æ ‡ç­¾
docker tag open-webui:latest your-username/open-webui:latest
docker tag open-webui:latest your-username/open-webui:v0.6.15

# 3. æ¨é€é•œåƒ
docker push your-username/open-webui:latest
docker push your-username/open-webui:v0.6.15
```

### æ¨é€åˆ°å…¶ä»–ä»“åº“
```bash
# æ¨é€åˆ°ç§æœ‰ä»“åº“
docker tag open-webui:latest registry.example.com/open-webui:latest
docker push registry.example.com/open-webui:latest

# æ¨é€åˆ°GitHub Container Registry
docker tag open-webui:latest ghcr.io/your-username/open-webui:latest
docker push ghcr.io/your-username/open-webui:latest
```

---

## ğŸ“¥ æ‹‰å–é•œåƒ (Docker Pull)

### ä»Docker Hubæ‹‰å–
```bash
# æ‹‰å–æœ€æ–°ç‰ˆæœ¬
docker pull ghcr.io/open-webui/open-webui:main

# æ‹‰å–æŒ‡å®šç‰ˆæœ¬
docker pull ghcr.io/open-webui/open-webui:v0.6.15

# æ‹‰å–CUDAç‰ˆæœ¬
docker pull ghcr.io/open-webui/open-webui:cuda

# æ‹‰å–Ollamaé›†æˆç‰ˆæœ¬
docker pull ghcr.io/open-webui/open-webui:ollama
```

### ä»å…¶ä»–ä»“åº“æ‹‰å–
```bash
# ä»ç§æœ‰ä»“åº“æ‹‰å–
docker pull registry.example.com/open-webui:latest

# ä»GitHub Container Registryæ‹‰å–
docker pull ghcr.io/your-username/open-webui:latest
```

---

## ğŸ’¾ æ•°æ®å·ç®¡ç†

### é»˜è®¤æ•°æ®è·¯å¾„
```
/app/backend/data/          # ä¸»æ•°æ®ç›®å½•
â”œâ”€â”€ docs/                   # æ–‡æ¡£å­˜å‚¨
â”œâ”€â”€ uploads/                # ä¸Šä¼ æ–‡ä»¶
â”œâ”€â”€ models/                 # æœ¬åœ°æ¨¡å‹
â”œâ”€â”€ cache/                  # ç¼“å­˜ç›®å½•
â”‚   â”œâ”€â”€ whisper/           # Whisperæ¨¡å‹ç¼“å­˜
â”‚   â”œâ”€â”€ embedding/         # åµŒå…¥æ¨¡å‹ç¼“å­˜
â”‚   â””â”€â”€ tiktoken/          # Tiktokenç¼“å­˜
â””â”€â”€ vector_dbs/            # å‘é‡æ•°æ®åº“
```

### æ¨èçš„å·æŒ‚è½½
```bash
# åŸºç¡€æŒ‚è½½
-v open-webui-data:/app/backend/data

# è¯¦ç»†æŒ‚è½½ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
-v open-webui-data:/app/backend/data \
-v open-webui-cache:/app/backend/data/cache \
-v open-webui-models:/app/backend/data/models \
-v open-webui-uploads:/app/backend/data/uploads

# å¦‚æœä½¿ç”¨Ollama
-v ollama-data:/root/.ollama
```

### æ•°æ®å¤‡ä»½
```bash
# å¤‡ä»½æ•°æ®å·
docker run --rm \
  -v open-webui-data:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/open-webui-backup.tar.gz -C /data .

# æ¢å¤æ•°æ®å·
docker run --rm \
  -v open-webui-data:/data \
  -v $(pwd):/backup \
  alpine tar xzf /backup/open-webui-backup.tar.gz -C /data
```

---

## âš™ï¸ ç¯å¢ƒå˜é‡é…ç½®

### åŸºç¡€é…ç½®
```bash
# APIé…ç½®
-e OPENAI_API_KEY=sk-your-openai-key
-e OPENAI_API_BASE_URL=https://api.openai.com/v1

# Ollamaé…ç½®
-e OLLAMA_BASE_URL=http://host.docker.internal:11434

# å®‰å…¨é…ç½®
-e WEBUI_SECRET_KEY=your-secret-key-here

# æ¨¡å‹é…ç½®
-e WHISPER_MODEL=base
-e RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### å®Œæ•´ç¯å¢ƒå˜é‡ç¤ºä¾‹
```bash
docker run -d \
  --name open-webui \
  -p 3000:8080 \
  -v open-webui-data:/app/backend/data \
  -e ENV=prod \
  -e PORT=8080 \
  -e OPENAI_API_KEY=your_openai_key \
  -e OPENAI_API_BASE_URL=https://api.openai.com/v1 \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  -e WEBUI_SECRET_KEY=your_secret_key \
  -e WHISPER_MODEL=base \
  -e RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2 \
  -e SCARF_NO_ANALYTICS=true \
  -e DO_NOT_TRACK=true \
  -e ANONYMIZED_TELEMETRY=false \
  --restart unless-stopped \
  open-webui:latest
```

---

## ğŸ”§ Docker Compose ç¤ºä¾‹

### åŸºç¡€ç‰ˆæœ¬
```yaml
# docker-compose.yml
version: '3.8'

services:
  open-webui:
    build: .
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OPENAI_API_KEY=your_openai_api_key
      - WEBUI_SECRET_KEY=your_secret_key
    restart: unless-stopped

volumes:
  open-webui-data:
```

### å®Œæ•´ç‰ˆæœ¬ï¼ˆåŒ…å«Ollamaï¼‰
```yaml
# docker-compose.full.yml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped

  open-webui:
    build:
      context: .
      args:
        USE_OLLAMA: "true"
        USE_CUDA: "true"
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=your_secret_key
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama-data:
  open-webui-data:
```

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### å®¹å™¨ç®¡ç†
```bash
# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
docker ps
docker logs open-webui

# è¿›å…¥å®¹å™¨
docker exec -it open-webui bash

# åœæ­¢å’Œå¯åŠ¨
docker stop open-webui
docker start open-webui
docker restart open-webui

# åˆ é™¤å®¹å™¨
docker rm open-webui
```

### é•œåƒç®¡ç†
```bash
# æŸ¥çœ‹é•œåƒ
docker images

# åˆ é™¤é•œåƒ
docker rmi open-webui:latest

# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
docker image prune
```

### æ•°æ®å·ç®¡ç†
```bash
# æŸ¥çœ‹æ•°æ®å·
docker volume ls

# æŸ¥çœ‹æ•°æ®å·è¯¦æƒ…
docker volume inspect open-webui-data

# åˆ é™¤æ•°æ®å·
docker volume rm open-webui-data
```

---

## ğŸ”§ è‡ªå®šä¹‰ä¿®æ”¹

### ç”¨æˆ·è§’è‰²æƒé™æ§åˆ¶

æœ¬é¡¹ç›®å·²å®ç°äº†åŸºäºç”¨æˆ·è§’è‰²çš„èœå•æƒé™æ§åˆ¶ï¼š

#### **è§’è‰²ç±»å‹**
- `admin` - ç®¡ç†å‘˜
- `user` - æ™®é€šç”¨æˆ·  
- `pending` - å¾…å®¡æ ¸ç”¨æˆ·

#### **æƒé™åˆ†é…**

**æ™®é€šç”¨æˆ· (user) å¯è§èœå•é¡¹ï¼š**
- âš™ï¸ Settings (è®¾ç½®)
- ğŸ“ Archived Chats (å½’æ¡£èŠå¤©)
- âŒ¨ï¸ Keyboard shortcuts (å¿«æ·é”®)
- ğŸšª Sign Out (é€€å‡º)

**ç®¡ç†å‘˜ (admin) é¢å¤–å¯è§ï¼š**
- ğŸ“š Documentation (æ–‡æ¡£)
- ğŸ“‹ Releases (å‘å¸ƒè¯´æ˜)
- ğŸ‘¥ Active Users (æ´»è·ƒç”¨æˆ·)
- ğŸ® Playground (è°ƒè¯•å·¥å…·)
- ğŸ‘¤ Admin Panel (ç®¡ç†é¢æ¿)

#### **ä¿®æ”¹æ–‡ä»¶**
å·²ä¿®æ”¹çš„æ ¸å¿ƒæ–‡ä»¶ï¼š
```
src/lib/components/layout/Sidebar/UserMenu.svelte
```

#### **å®ç°ç»†èŠ‚**
```svelte
<!-- æ™®é€šç”¨æˆ·èœå•é¡¹ -->
{#if role === 'user' || role === 'admin'}
    <!-- Settings, Archived Chats, Keyboard shortcuts, Sign Out -->
{/if}

<!-- ç®¡ç†å‘˜ä¸“å±èœå•é¡¹ -->
{#if role === 'admin'}
    <!-- Documentation, Releases, Active Users, Playground, Admin Panel -->
{/if}
```

#### **éªŒè¯æ–¹å¼**
1. åˆ›å»ºä¸åŒè§’è‰²çš„ç”¨æˆ·è´¦å·
2. åˆ†åˆ«ç™»å½•æŸ¥çœ‹å³ä¸Šè§’å¤´åƒèœå•
3. æ£€æŸ¥ä¾§è¾¹æ å·¦ä¸‹è§’ç”¨æˆ·èœå•
4. ç¡®è®¤æƒé™æ§åˆ¶ç”Ÿæ•ˆ

## â— å¸¸è§é—®é¢˜

### 1. ç«¯å£å†²çª
```bash
# å¦‚æœ3000ç«¯å£è¢«å ç”¨ï¼Œæ›´æ”¹æ˜ å°„ç«¯å£
docker run -p 8080:8080 open-webui:latest
```

### 2. GPUä¸å¯ç”¨
```bash
# ç¡®ä¿å®‰è£…äº†nvidia-docker2
sudo apt install nvidia-docker2
sudo systemctl restart docker

# æµ‹è¯•GPUå¯ç”¨æ€§
docker run --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### 3. æ•°æ®æŒä¹…åŒ–é—®é¢˜
```bash
# ç¡®ä¿ä½¿ç”¨äº†æ­£ç¡®çš„æ•°æ®å·æŒ‚è½½
-v open-webui-data:/app/backend/data
```

### 4. Ollamaè¿æ¥é—®é¢˜
```bash
# ä½¿ç”¨hostç½‘ç»œæ¨¡å¼
docker run --network host open-webui:latest

# æˆ–è€…æ­£ç¡®é…ç½®host.docker.internal
--add-host=host.docker.internal:host-gateway
```

---

## ğŸ“ ä½¿ç”¨æ­¥éª¤æ€»ç»“

1. **æ„å»ºé•œåƒ**ï¼š`docker build -t open-webui:latest .`
2. **è¿è¡Œå®¹å™¨**ï¼š`docker run -d -p 3000:8080 -v open-webui-data:/app/backend/data open-webui:latest`
3. **è®¿é—®åº”ç”¨**ï¼šæ‰“å¼€æµè§ˆå™¨è®¿é—® `http://localhost:3000`
4. **æ•°æ®å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½ `open-webui-data` æ•°æ®å·
5. **æ›´æ–°åº”ç”¨**ï¼šé‡æ–°æ„å»ºé•œåƒå¹¶é‡æ–°éƒ¨ç½²å®¹å™¨

---

> ğŸ’¡ **æç¤º**ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ Docker Compose è¿›è¡Œéƒ¨ç½²ç®¡ç†ï¼Œæ›´åŠ æ–¹ä¾¿ç»´æŠ¤å’Œæ‰©å±•ã€‚ 